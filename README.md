# Research Assistant Chatbot

A local, privacy-respecting chatbot that helps researchers explore academic papers through Retrieval-Augmented Generation (RAG). Given one or more seed papers, the app builds a knowledge base of related papers (citations and cited-by) and allows the user to ask deep, research-oriented questions like:

> "Has anyone ever applied method X to domain Y?"  
> "What are the main evaluation metrics used for topic Z?"  
> "Is there a consensus on problem P?"

---

## ğŸ§  Features

- ğŸ§¾ Fetches related papers using citation networks
- ğŸ“¥ Downloads and parses PDFs automatically
- ğŸ§© Segments paper text into retrievable chunks
- ğŸ” Stores embeddings in a vector database (FAISS)
- ğŸ’¬ Answers user questions using a local LLM via RAG (Ollama)
- ğŸ›ï¸ Optional filtering by author, year, keywords, and more
- ğŸ“Š Visualizes the citation network
- âš™ï¸ 100% local, free, and open source

---

## ğŸš€ Quickstart

### 1. Clone the repo

```bash
git clone https://github.com/your-username/research-assistant-chatbot.git
cd research-assistant-chatbot
```

### 2. Install dependencies

```bash
python -m venv venv
source venv/bin/activate   # or .\venv\Scripts\activate on Windows
pip install -r requirements.txt
```

### 3. Start the app

```bash
streamlit run app/ui.py
```

### 4. Requirements
- Python 3.9+
- Ollama installed with a local LLM (e.g. `mistral`, `llama3`)
- Basic tools like `pdftotext` or `pdfminder` if using CLI PDF parsing

## ğŸ§± Project Structure

```pgsql
app/
â”œâ”€â”€ main.py               â† Entry point for CLI (optional)
â”œâ”€â”€ ui.py                 â† Streamlit interface
â”œâ”€â”€ paper_loader.py       â† Citation retrieval + PDF downloader
â”œâ”€â”€ chunking.py           â† Splits papers into text chunks
â”œâ”€â”€ embedding.py          â† Embeds chunks and stores them in vector DB
â”œâ”€â”€ rag_pipeline.py       â† Handles retrieval and LLM response generation
â””â”€â”€ utils.py              â† Helper functions

data/
â”œâ”€â”€ raw_papers/           â† Downloaded PDFs
â”œâ”€â”€ metadata.jsonl        â† Cached paper metadata
â””â”€â”€ chunks/               â† Parsed and chunked text segments

vector_db/
â”œâ”€â”€ faiss_index/          â† FAISS vector store
â””â”€â”€ chunk_metadata.json   â† Mapping of chunks to papers
```


---

## ğŸ§ª Example Use Cases

- â€œHas anyone applied transformer models to supply chain optimization?â€
- â€œWhich papers cited both [Author A] and [Author B]?â€
- â€œWhat techniques are most common for domain adaptation in NLP?â€

---

## ğŸ“– License

This project is licensed under the MIT License â€“ see the [LICENSE](./LICENSE) file for details.

---

## ğŸ™‹â€â™€ï¸ Contributing

Pull requests are welcome! If youâ€™d like to suggest a feature or fix a bug, please open an issue first.

---

## ğŸ“« Contact

Built by [Ido Guy](mailto:redrhig@gmail.com)  
Feel free to reach out for collaboration or feedback.
